## CHAPTER 2: End-to-End Machine Learning Project

### Look at the Big Picture
- Pipelines: A sequence of data processing components is called a data pipeline. Pipelines are very common in Machine Learning systems, since there is a lot of data to manipulate and many data transformations to apply.
- Both the RMSE and the MAE are ways to measure the distance between two vectors: the vector of predictions and the vector of target values.  Various distance measures, or norms, are possible:
    1. Computing the root of a sum of squares (RMSE) corresponds to the Euclidian norm: it is the notion of distance you are familiar with. It is also called the **ℓ2 norm**.
    2. Computing the sum of absolutes (MAE) corresponds to the **ℓ1 norm**. It is sometimes called the Manhattan norm because it measures the distance between two points in a city if you can only travel along orthogonal city blocks.
> **RMSE vs MAE**  
>- RMSE has the benefit of penalizing large errors more so can be more appropriate in some cases, for example, if being off by 10 is more than twice as bad as being off by 5. But if being off by 10 is just twice as bad as being off by 5, then MAE is more appropriate.
>- From an interpretation standpoint, MAE is clearly the winner. RMSE does not describe average error alone and has other implications that are more difficult to tease out and understand.
>- On the other hand, one distinct advantage of RMSE over MAE is that RMSE avoids the use of taking the absolute value, which is undesirable in many mathematical calculations. 
    
- The higher the norm index, the more it focuses on large values and neglects small ones. This is why the RMSE is more sensitive to outliers than the MAE. But when outliers are exponentially rare, the RMSE performs very well and is generally preferred. 
- A quick way to get a feel of the type of data you are dealing with is to plot a histogram for each numerical attribute.
- Working with preprocessed attributes is common in Machine Learning, and it is not necessarily a problem, but you should try to understand how the data was computed.
- When you estimate the generalization error using the test set, your estimate will be too optimistic and you will launch a system that will not perform as well as expected. This is called data snooping bias.
- Stratified sampling: the population is divided into homogeneous subgroups called strata, and the right number of instances is sampled from each stratum to guarantee that the test set is representative of the overall population. For example, the US population is composed of 51.3% female and 48.7% male, so a well-conducted survey data of 1000 people in the US would try to maintain this ratio in the sample: 513 female and 487 male.
- Hence, when creating the test set from the dataset, instead of randomly shuffling the data and keeping a percentage of data aside for test data, you should perform stratified sampling so that the test data preserves the similar distribution of important categories as in the actual dataset.

### Discover and Visualize the Data to Gain Insights
- It is a good idea to look at correlation between features and the target. The correlation coefficient ranges from –1 to 1. When it is close to 1, it means that there is a strong positive correlation; for example, the median house value tends to go up when the median income goes up. When the coefficient is close to –1, it means that there is a strong negative correlation; you can see a small negative correlation between the latitude and the median house value (i.e., prices have a slight tendency to go down when you go north). Finally, coefficients close to zero mean that there is no linear correlation.  
__Note: The correlation coefficient only measures linear correlations (“if x goes up, then y generally goes up/down”). It may completely miss out on nonlinear relationships (e.g., “if x is close to zero then y generally goes up”).
- Another way to check for correlation between attributes is to use Pandas’ scatter_matrix function, which plots every numerical attribute against every other numerical attribute.__
- One last thing you may want to do before actually preparing the data for Machine Learning algorithms is to try out various attribute combinations. Combine different features and see if you can notice some meaningful pattern or observe a better correlation with the target. 


### Prepare the Data for Machine Learning Algorithms
- Scikit-Learn provides a handy class to take care of missing values: Imputer. First, you need to create an Imputer instance, specifying that you want to replace each attribute’s missing values with the median of that attribute. Then you can fit the imputer instance to the training data using the fit() method. 
- **Scikit-Learn Design principles**:
	1. Consistency: All objects share a consistent and simple interface:  
		(i) Estimators: Any object that can estimate some parameters based on a dataset is called an estimator (e.g., an imputer is an estimator). The estimation itself is performed by the fit() method, and it takes only a dataset as a parameter. Any other parameter needed to guide the estimation process is considered a hyperparameter (such as an imputer’s strategy), and it must be set as an instance variable.  
		(ii) Transformers: Some estimators (such as an imputer) can also transform a dataset; these are called transformers. Once again, the API is quite simple: the transformation is performed by the transform() method with the dataset to transform as a parameter. It returns the transformed dataset. This transformation generally relies on the learned parameters, as is the case for an imputer. All transformers also have a convenience method called fit_transform().  
		(iii) Predictors: Finally, some estimators are capable of making predictions given a dataset; they are called predictors. A predictor has a predict() method that takes a dataset of new instances and returns a dataset of corresponding predictions. It also has a score() method that measures the quality of the predictions given a test set.  
	2. Inspection: All the estimator’s hyperparameters are accessible directly via public instance variables (e.g., imputer.strategy), and all the estimator’s learned parameters are also accessible via public instance variables with an underscore suffix (e.g., imputer.statistics_).
	3. Nonproliferation of classes: Datasets are represented as NumPy arrays or SciPy sparse matrices, instead of homemade classes. Hyperparameters are just regular Python strings or numbers.
	4. Composition: Existing building blocks are reused as much as possible. For example, it is easy to create a Pipeline estimator from an arbitrary sequence of transformers followed by a final estimator.
	5. Sensible defaults: Scikit-Learn provides reasonable default values for most parameters, making it easy to create a baseline working system quickly.
- Scikit-learn provides 'LabelEncoder()' for converting categorical features to numeric ones. One issue with this representation is that ML algorithms will assume that two nearby values are more similar than two distant values (but that might not be the case). To fix this issue, a common solution is to create one binary attribute per category: This is called one-hot encoding, because only one attribute will be equal to 1 (hot), while the others will be 0 (cold).
- NumPy’s reshape() function allows one dimension to be –1, which means “unspecified”: the value is inferred from the length of the array and the remaining dimensions.
- We can apply both transformations (from text categories to integer categories, then from integer categories to one-hot vectors) in one shot using the 'LabelBinarizer' class.
- Although Scikit-Learn provides many useful transformers, you will need to write your own for tasks such as custom cleanup operations or combining specific attributes. You will want your transformer to work seamlessly with Scikit-Learn functionalities (such as pipelines), and since Scikit-Learn relies on duck typing (not inheritance), all you need is to create a class and implement three methods: fit() (returning self), transform(), and fit_transform().
- The more you automate the data preparation steps (by writing custom transformers), the more combinations you can automatically try out, making it much more likely that you will find a great combination (and saving you a lot of time).

- One of the most important transformations you need to apply to your data is feature scaling. Machine Learning algorithms don’t perform well when the input numerical attributes have very different scales. Note that scaling the target values is generally not required.
- There are two common ways to get all attributes to have the same scale:
	1. Min-max scaling: (many people call this normalization) is quite simple. The values are shifted and rescaled so that they end up ranging from 0 to 1. 
	2. Standardization is quite different: first it subtracts the mean value (so standardized values always have a zero mean), and then it divides by the variance so that the resulting distribution has unit variance. Unlike min-max scaling, standardization does not bound values to a specific range, which may be a problem for some algorithms.
	Note that Min-max scaling is more sensitive to outliers than Standardization. 
- As with all the transformations, it is important to fit the scalers to the training data only, not to the full dataset (including the test set). Only then can you use them to transform the training set and the test set (and new data).
- There maybe many data transformation steps that need to be executed in the right order. Fortunately, Scikit-Learn provides the 'Pipeline' class to help with such sequences of transformations. The Pipeline constructor takes a list of name/estimator pairs defining a sequence of steps. All but the last estimator must be transformers (i.e., they must have a fit_transform() method). When you call the pipeline’s fit() method, it calls fit_transform() sequentially on all transformers, passing the output of each call as the parameter to the next call, until it reaches the final estimator, for which it just calls the fit() method.
- Scikit-Learn also provides a 'FeatureUnion' class for combining different transformations (like numerical, categorical) into a single pipeline.
- Building a model on top of many other models is called Ensemble Learning, and it is often a great way to push ML algorithms even further.
- You should save every model you experiment with, so you can come back easily to any model you want. Make sure you save both the hyperparameters and the trained parameters, as well as the cross-validation scores and perhaps the actual predictions as well. This will allow you to easily compare scores across model types, and compare the types of errors they make.
- **Fine-Tuning Your Model**:
    1. Grid Search: One way to do that would be to fiddle with the hyperparameters manually, until you find a great combination of hyperparameter values. Scikit-Learn provides 'GridSearchCV' API for this purpose. All you need to do is tell it which hyperparameters you want it to experiment with, and what values to try out, and it will evaluate all the possible combinations of hyperparameter values, using cross-validation.
    2. Randomized Search: The grid search approach is fine when you are exploring relatively few combinations, but when the hyperparameter search space is large, it is often preferable to use RandomizedSearchCV instead. This class can be used in much the same way as the GridSearchCV class,  but instead of trying out all possible combinations, it evaluates a given number of random  combinations by selecting a random value for each hyperparameter at every iteration. 
    3. Ensemble Methods: Another way to fine-tune your system is to try to combine the models that perform best. The group (or “ensemble”) will often perform better than the best individual
model, especially if the individual models make very different types of errors.
