{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Neural Network Model\n",
    "We're going to be working first with the MNIST dataset, which is a dataset that contains 60,000 training samples and 10,000 testing samples of hand-written and labeled digits, 0 through 9, so ten total \"classes.\"  \n",
    "\n",
    "This is a very small dataset in terms of what you would be working with in any realistic setting, but it should also be small enough to work on everyone's computers.  \n",
    "\n",
    "### About the dataset\n",
    "- The MNIST dataset has the images, which we'll be working with as purely black and white, thresholded, images, of size 28 x 28, or 784 pixels total.  \n",
    "- Our features will be the pixel values for each pixel, thresholded. Either the pixel is \"blank\" (0), or there is something (1).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to attempt to just use this extremely rudimentary data, and predict the number we're looking at (a 0,1,2,3,4,5,6,7,8, or 9). We're hoping that our neural network will somehow create an inner-model of the relationships between pixels, and be able to look at new examples of digits and predict them to a high degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import tensorflow and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're working with our own collected data, chances are, it won't be packaged up so nicely, and we may have to spend a bit more time and effort on this step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `x_train` data is the \"features\". In this case, the features are pixel values of the 28x28 images of these digits 0-9.  \n",
    "The `y_train` is the label (is it a 0,1,2,3,4,5,6,7,8 or a 9?)\n",
    "\n",
    "The testing variants of these variables is the \"out of sample\" examples that we will use. These are examples from our data that we're going to set aside, reserving them for testing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are exceptionally good at fitting to data, so much so that they will commonly over-fit the data. Our real hope is that the neural network doesn't just memorize our data and that it instead \"generalizes\" and learns the actual problem and patterns associated with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at this actual data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output doesn't seem to be meaningful for our eyes. Lets visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOUElEQVR4nO3dX4xUdZrG8ecFwT8MKiyt2zJEZtGYIRqBlLAJG0Qni38SBS5mAzGIxogXIDMJxEW5gAsvjO7MZBQzplEDbEYmhJEIiRkHCcYQE0OhTAuLLGpapkeEIkTH0QsU373ow6bFrl81VafqlP1+P0mnquup0+dNhYdTXae6fubuAjD0DSt6AACtQdmBICg7EARlB4Kg7EAQF7RyZ+PGjfOJEye2cpdAKD09PTp58qQNlDVUdjO7XdJvJQ2X9Ly7P5G6/8SJE1UulxvZJYCEUqlUNav7abyZDZf0rKQ7JE2WtNDMJtf78wA0VyO/s0+X9IG7f+TupyX9QdLcfMYCkLdGyj5e0l/7fd+b3fYdZrbEzMpmVq5UKg3sDkAjGin7QC8CfO+9t+7e5e4ldy91dHQ0sDsAjWik7L2SJvT7/seSPmlsHADN0kjZ90q61sx+YmYjJS2QtD2fsQDkre5Tb+7+jZktk/Sa+k69vejuB3ObDECuGjrP7u6vSno1p1kANBFvlwWCoOxAEJQdCIKyA0FQdiAIyg4EQdmBICg7EARlB4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBEHZgSAoOxAEZQeCoOxAEJQdCIKyA0FQdiCIhlZxRfs7c+ZMMv/888+buv9169ZVzb766qvktocPH07mzz77bDJfuXJl1Wzz5s3JbS+66KJkvmrVqmS+Zs2aZF6EhspuZj2SvpB0RtI37l7KYygA+cvjyH6Lu5/M4ecAaCJ+ZweCaLTsLunPZrbPzJYMdAczW2JmZTMrVyqVBncHoF6Nln2mu0+TdIekpWY269w7uHuXu5fcvdTR0dHg7gDUq6Gyu/sn2eUJSdskTc9jKAD5q7vsZjbKzEafvS5pjqQDeQ0GIF+NvBp/paRtZnb257zk7n/KZaoh5ujRo8n89OnTyfytt95K5nv27KmaffbZZ8ltt27dmsyLNGHChGT+8MMPJ/Nt27ZVzUaPHp3c9sYbb0zmN998czJvR3WX3d0/kpR+RAC0DU69AUFQdiAIyg4EQdmBICg7EAR/4pqDd999N5nfeuutybzZf2baroYPH57MH3/88WQ+atSoZH7PPfdUza666qrktmPGjEnm1113XTJvRxzZgSAoOxAEZQeCoOxAEJQdCIKyA0FQdiAIzrPn4Oqrr07m48aNS+btfJ59xowZybzW+ejdu3dXzUaOHJncdtGiRckc54cjOxAEZQeCoOxAEJQdCIKyA0FQdiAIyg4EwXn2HIwdOzaZP/XUU8l8x44dyXzq1KnJfPny5ck8ZcqUKcn89ddfT+a1/qb8wIHqSwk8/fTTyW2RL47sQBCUHQiCsgNBUHYgCMoOBEHZgSAoOxAE59lbYN68ecm81ufK11peuLu7u2r2/PPPJ7dduXJlMq91Hr2W66+/vmrW1dXV0M/G+al5ZDezF83shJkd6HfbWDPbaWZHssv0JxgAKNxgnsZvkHT7ObetkrTL3a+VtCv7HkAbq1l2d39T0qlzbp4raWN2faOk9PNUAIWr9wW6K939mCRll1dUu6OZLTGzspmVK5VKnbsD0Kimvxrv7l3uXnL3UkdHR7N3B6CKest+3Mw6JSm7PJHfSACaod6yb5e0OLu+WNIr+YwDoFlqnmc3s82SZksaZ2a9ktZIekLSFjN7QNJRST9v5pBD3aWXXtrQ9pdddlnd29Y6D79gwYJkPmwY78v6oahZdndfWCX6Wc6zAGgi/lsGgqDsQBCUHQiCsgNBUHYgCP7EdQhYu3Zt1Wzfvn3Jbd94441kXuujpOfMmZPM0T44sgNBUHYgCMoOBEHZgSAoOxAEZQeCoOxAEJxnHwJSH/e8fv365LbTpk1L5g8++GAyv+WWW5J5qVSqmi1dujS5rZklc5wfjuxAEJQdCIKyA0FQdiAIyg4EQdmBICg7EATn2Ye4SZMmJfMNGzYk8/vvvz+Zb9q0qe78yy+/TG577733JvPOzs5kju/iyA4EQdmBICg7EARlB4Kg7EAQlB0IgrIDQXCePbj58+cn82uuuSaZr1ixIpmnPnf+0UcfTW778ccfJ/PVq1cn8/HjxyfzaGoe2c3sRTM7YWYH+t221sz+Zmb7s687mzsmgEYN5mn8Bkm3D3D7b9x9Svb1ar5jAchbzbK7+5uSTrVgFgBN1MgLdMvMrDt7mj+m2p3MbImZlc2sXKlUGtgdgEbUW/bfSZokaYqkY5J+Ve2O7t7l7iV3L3V0dNS5OwCNqqvs7n7c3c+4+7eS1kuanu9YAPJWV9nNrP/fFs6XdKDafQG0h5rn2c1ss6TZksaZWa+kNZJmm9kUSS6pR9JDTZwRBbrhhhuS+ZYtW5L5jh07qmb33XdfctvnnnsumR85ciSZ79y5M5lHU7Ps7r5wgJtfaMIsAJqIt8sCQVB2IAjKDgRB2YEgKDsQhLl7y3ZWKpW8XC63bH9obxdeeGEy//rrr5P5iBEjkvlrr71WNZs9e3Zy2x+qUqmkcrk84FrXHNmBICg7EARlB4Kg7EAQlB0IgrIDQVB2IAg+ShpJ3d3dyXzr1q3JfO/evVWzWufRa5k8eXIynzVrVkM/f6jhyA4EQdmBICg7EARlB4Kg7EAQlB0IgrIDQXCefYg7fPhwMn/mmWeS+csvv5zMP/300/OeabAuuCD9z7OzszOZDxvGsaw/Hg0gCMoOBEHZgSAoOxAEZQeCoOxAEJQdCILz7D8Atc5lv/TSS1WzdevWJbft6empZ6Rc3HTTTcl89erVyfzuu+/Oc5whr+aR3cwmmNluMztkZgfN7BfZ7WPNbKeZHckuxzR/XAD1GszT+G8krXD3n0r6V0lLzWyypFWSdrn7tZJ2Zd8DaFM1y+7ux9z9nez6F5IOSRovaa6kjdndNkqa16whATTuvF6gM7OJkqZKelvSle5+TOr7D0HSFVW2WWJmZTMrVyqVxqYFULdBl93MfiTpj5J+6e5/H+x27t7l7iV3L3V0dNQzI4AcDKrsZjZCfUX/vbuf/TOo42bWmeWdkk40Z0QAeah56s3MTNILkg65+6/7RdslLZb0RHb5SlMmHAKOHz+ezA8ePJjMly1blszff//9854pLzNmzEjmjzzySNVs7ty5yW35E9V8DeY8+0xJiyS9Z2b7s9seU1/Jt5jZA5KOSvp5c0YEkIeaZXf3PZIGXNxd0s/yHQdAs/A8CQiCsgNBUHYgCMoOBEHZgSD4E9dBOnXqVNXsoYceSm67f//+ZP7hhx/WNVMeZs6cmcxXrFiRzG+77bZkfvHFF5/3TGgOjuxAEJQdCIKyA0FQdiAIyg4EQdmBICg7EESY8+xvv/12Mn/yySeT+d69e6tmvb29dc2Ul0suuaRqtnz58uS2tT6uedSoUXXNhPbDkR0IgrIDQVB2IAjKDgRB2YEgKDsQBGUHgghznn3btm0N5Y2YPHlyMr/rrruS+fDhw5P5ypUrq2aXX355clvEwZEdCIKyA0FQdiAIyg4EQdmBICg7EARlB4Iwd0/fwWyCpE2S/lnSt5K63P23ZrZW0oOSKtldH3P3V1M/q1QqeblcbnhoAAMrlUoql8sDrro8mDfVfCNphbu/Y2ajJe0zs51Z9ht3/6+8BgXQPINZn/2YpGPZ9S/M7JCk8c0eDEC+zut3djObKGmqpLOf8bTMzLrN7EUzG1NlmyVmVjazcqVSGeguAFpg0GU3sx9J+qOkX7r73yX9TtIkSVPUd+T/1UDbuXuXu5fcvdTR0ZHDyADqMaiym9kI9RX99+7+siS5+3F3P+Pu30paL2l688YE0KiaZTczk/SCpEPu/ut+t3f2u9t8SQfyHw9AXgbzavxMSYskvWdmZ9cefkzSQjObIskl9UhKr1sMoFCDeTV+j6SBztslz6kDaC+8gw4IgrIDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBEHZgSAoOxBEzY+SznVnZhVJH/e7aZykky0b4Py062ztOpfEbPXKc7ar3X3Az39radm/t3OzsruXChsgoV1na9e5JGarV6tm42k8EARlB4IouuxdBe8/pV1na9e5JGarV0tmK/R3dgCtU/SRHUCLUHYgiELKbma3m9lhM/vAzFYVMUM1ZtZjZu+Z2X4zK3R96WwNvRNmdqDfbWPNbKeZHckuB1xjr6DZ1prZ37LHbr+Z3VnQbBPMbLeZHTKzg2b2i+z2Qh+7xFwtedxa/ju7mQ2X9L+S/l1Sr6S9kha6+/+0dJAqzKxHUsndC38DhpnNkvQPSZvc/frsticlnXL3J7L/KMe4+3+2yWxrJf2j6GW8s9WKOvsvMy5pnqT7VOBjl5jrP9SCx62II/t0SR+4+0fuflrSHyTNLWCOtufub0o6dc7NcyVtzK5vVN8/lparMltbcPdj7v5Odv0LSWeXGS/0sUvM1RJFlH28pL/2+75X7bXeu0v6s5ntM7MlRQ8zgCvd/ZjU949H0hUFz3Oumst4t9I5y4y3zWNXz/LnjSqi7AMtJdVO5/9muvs0SXdIWpo9XcXgDGoZ71YZYJnxtlDv8ueNKqLsvZIm9Pv+x5I+KWCOAbn7J9nlCUnb1H5LUR8/u4Judnmi4Hn+Xzst4z3QMuNqg8euyOXPiyj7XknXmtlPzGykpAWSthcwx/eY2ajshROZ2ShJc9R+S1Fvl7Q4u75Y0isFzvId7bKMd7VlxlXwY1f48ufu3vIvSXeq7xX5DyWtLmKGKnP9i6S/ZF8Hi55N0mb1Pa37Wn3PiB6Q9E+Sdkk6kl2ObaPZ/lvSe5K61VeszoJm+zf1/WrYLWl/9nVn0Y9dYq6WPG68XRYIgnfQAUFQdiAIyg4EQdmBICg7EARlB4Kg7EAQ/weypTV95ccHFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a `5`. Lets confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's generally a good idea to \"normalize\" our data. This typically involves scaling the data to be between 0 and 1, or maybe -1 and positive 1.  \n",
    "In our case, each \"pixel\" is a feature, and each feature currently ranges from 0 to 255. Not quite 0 to 1. Let's change that with a handy utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train[0])\n",
    "\n",
    "# plt.imshow(x_train[0],cmap=plt.cm.binary)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its between `0` and `1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build our model!  \n",
    "\n",
    "- A sequential model is what we're going to use most of the time. It just means things are going to go in direct order. A feed forward model. No going backwards.  \n",
    "- Next, we'll add layers. We need to take this 28x28 image, and make it a flat 1x784 for the input layer. There are many ways for us to do this, but keras has a Flatten layer built just for us, so we'll use that.  \n",
    "- Next, we want our hidden layers. We're going to go with the simplest neural network layer, which is just a Dense layer. This refers to the fact that it's a densely-connected layer, meaning it's \"fully connected,\" where each node connects to each prior and subsequent node.  \n",
    "- The layer we add will have 128 units. The activation function is *relu*, short for rectified linear. Currently, *relu* is the activation function you should just default to. There are many more to test for sure, but, if you don't know what to use, use relu to start.  \n",
    "- We will also add another identical layer for good measure.\n",
    "- Finally we add an output layer. It should have 10 nodes - one node per possible number prediction. In this case, our activation function is a softmax function, since we're really actually looking for something more like a probability distribution of which of the possible prediction options this thing we're passing features through of is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to \"compile\" the model. This is where we pass the settings for actually optimizing/training the model we've defined.  \n",
    "Similar to *relu* activation function, *adam* is a good optimizer to start with as default.  \n",
    "Next, we have our loss metric. Loss is a calculation of error. A neural network doesn't actually attempt to **maximize accuracy**. It attempts to **minimize loss**. Again, there are many choices, but some form of categorical crossentropy is a good start for a classification task like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0562 - accuracy: 0.9820\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0425 - accuracy: 0.9861\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0325 - accuracy: 0.9894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22ab6f817c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Getting a high accuracy and low loss might mean our model learned how to classify digits in general (it generalized) or it simply memorized every single example we showed it (it overfit). This is why we need to test on out-of-sample data (data we didn't use to train the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.9761\n",
      "0.08789397031068802\n",
      "0.9761000275611877\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss)\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model\n",
    "We can save our model adn use it in the future instead of training again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\projects\\myprojects\\deeplearning\\dlenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: epic_num_reader.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict(x_test)\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, not much readable since these are probability distributions. We can get the actual number pretty simply using numpy's argmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets verify if the prediction is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
