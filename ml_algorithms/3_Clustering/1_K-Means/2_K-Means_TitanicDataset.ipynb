{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Titanic dataset <a href=\"https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls\">here</a>  \n",
    "\n",
    "This is what each column means:\n",
    "- **Pclass**: Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "- **survival**: Survival (0 = No; 1 = Yes)\n",
    "- **name**: Name\n",
    "- **sex**: Sex\n",
    "- **age**: Age\n",
    "- **sibsp**: Number of Siblings/Spouses Aboard\n",
    "- **parch**: Number of Parents/Children Aboard\n",
    "- **ticket**: Ticket Number\n",
    "- **fare**: Passenger Fare (British pound)\n",
    "- **cabin**: Cabin\n",
    "- **embarked**: Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "- **boat**: Lifeboat\n",
    "- **body**: Body Identification Number\n",
    "- **home**:.dest Home/Destination\n",
    "\n",
    "The main focus on this dataset is typically on the survival column. When using supervised machine learning, we might train the data against the survival column as the classification. With clustering, however, we let the machine make the groups, and basically a label of its own.  \n",
    "Our first interest is if the groups are clearly related to any of the columns, especially the survival column. For this data, we'll do flat-clustering, which is where we tell the machine we want two groups, but later we'll also let the machine determine the number of groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing, model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "You may need to do `pip install xlrd` before reading the excel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/titanic.xls')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "First, lets drop the useless columns `body` and `name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['body', 'name'], 1, inplace=True)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue is, we've got non-numerical data here. The machine learning algorithm is going to require numbers. We can just drop the name column, it has no use to us.  \n",
    "There are many ways to handle for non-numerical data.  \n",
    "First, we will cycle through the columns in the Pandas dataframe. For columns that are not numbers, we will find their unique elements. This can be done by simply take a set of the column values. From here, the index within that set can be the new \"numerical\" value or \"id\" of the text data.  \n",
    "\n",
    "- The embedded function `convert_to_int` converts the parameter value to whatever the value of that item (as a key) is from the text_digit_vals dictionary.\n",
    "- If the value in not an `int` or a `float` we will convert the column to a list of its values, then we take the set of that column to get just the unique values.\n",
    "- For each of the unique elements we find, we create a new dictionary key that is that unique element, with a value of a new number. \n",
    "- Once we've iterated through all of the unique values in the column, we then use mapping to map the function we created before to the pandas column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_non_numerical_data(df):\n",
    "    columns = df.columns.values\n",
    "    for column in columns:\n",
    "        text_digit_vals = {}\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "\n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
    "            column_contents = df[column].values.tolist()\n",
    "            unique_elements = set(column_contents)\n",
    "            x = 0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x+=1\n",
    "\n",
    "            df[column] = list(map(convert_to_int, df[column]))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>519</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>519</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>519</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>519</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived  sex      age  sibsp  parch  ticket      fare  cabin  \\\n",
       "0       1         1    1  29.0000      0      0     755  211.3375    155   \n",
       "1       1         1    0   0.9167      1      2     519  151.5500    136   \n",
       "2       1         0    1   2.0000      1      2     519  151.5500    136   \n",
       "3       1         0    0  30.0000      1      2     519  151.5500    136   \n",
       "4       1         0    1  25.0000      1      2     519  151.5500    136   \n",
       "\n",
       "   embarked  boat  home.dest  \n",
       "0         1     2         19  \n",
       "1         1    25        367  \n",
       "2         1     0        367  \n",
       "3         1     0        367  \n",
       "4         1     0        367  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = handle_non_numerical_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Lets drop the `survived` column, seperate the data against labels, scale the data and train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(df.drop(['survived'], 1).astype(float))\n",
    "X = preprocessing.scale(X)\n",
    "y = np.array(df['survived'])\n",
    "\n",
    "clf = KMeans(n_clusters=2)\n",
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important point to note here is that `survived` is either a 0, which means non-survival, or a 1, which means survival.  \n",
    "For a clustering algorithm, **the machine will find the clusters, but then will asign arbitrary values to them, in the order it finds them**. Thus, the group that is survivors might be a 0 or a 1, depending on a degree of randomness. Thus, if you consistently get 30% and 70% accuracy, then your model is 70% accurate.  \n",
    "Let's see what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.2696715049656226\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    predict_row = np.array(X[i].astype(float))\n",
    "    predict_row = predict_row.reshape(-1, len(predict_row))\n",
    "    prediction = clf.predict(predict_row)\n",
    "    \n",
    "    if prediction[0] == y[i]:\n",
    "        correct+=1\n",
    "\n",
    "print(\"Accuracy: \", correct/len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the scaling step (while fitting the classifier) makes a big impact. If you remove that step, accuracy drops to 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this clustering algorithm seems to automatically categorize these people into who might survive or not on the ship's sinking.  \n",
    "We don't have much in the way of determining exactly what the machine is thinking about and why these are the groups chosen, but they appear to have a high degree of correlation with survivability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing, you can simply drop columns like `sex`, `boat` etc. one by one and try to see the impact on our accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For getting proper accuracy everytime (instead of alternating between 70 and 30 or whatever numbers) you can add this simple logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7303284950343774\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", max(correct/len(X), 1-(correct/len(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
