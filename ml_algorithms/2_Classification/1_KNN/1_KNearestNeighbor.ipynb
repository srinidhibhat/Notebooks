{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "The purpose of classification is to train a machine on previously known data so that the machine can later identify the class of new data.  \n",
    "<br>\n",
    "For example, we'll be working with breast tumor data to try to identify malignant and benign breast tumors based on attributes. The way we can do this is to take previously known samples of attributes like size and shape of the tumor as the features, and the label/class is either benign or malignant. From here, we can assess future tumors by their same attributes and predict whether or not the tumor is benign or malignant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbors is a simple and effective machine learning classification algorithm overall.  \n",
    "The way it works is completely in the name. K is a number you can choose, and then neighbors are the data points from known data. We're looking for any number of the \"nearest\" neighbors. Let's say K = 3, so then we're looking for the two closest neighboring points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Dataset can be downloaded <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/\">here.</a>  \n",
    "- *breast-cancer-wisconsin.data*: is the actual dataset\n",
    "- *breast-cancer-wisconsin.names*: is the details about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting with programming, lets modify the *breast-cancer-wisconsin.data* file. You can observe then it doesn't contain a header about what each column means. To treat it as any other csv file, just add a row at the top like this:  \n",
    "`id,clump_thickness,uniform_cell_size,uniform_cell_shape,marginal_adhesion,single_epi_cell_size,bare_nuclei,bland_chromation,normal_nucleoli,mitoses,class`  \n",
    "This should give a name for each column and makes it meaningful once converted to dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import the libraries we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, model_selection, neighbors\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "Lets load the data and clean it.  \n",
    "It is mentioned in *breast-cancer-wisconsin.names* file that missing values are represented by *'?'*. Lets replace it with a custom value.  \n",
    "Lets also remove the *'id'* column as it doesn't add any useful weight to training (it will ruin the training if considered.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/breast-cancer-wisconsin.data')\n",
    "df.replace('?',-99999, inplace=True)\n",
    "df.drop(['id'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels\n",
    "Now, we'll define our deatures and label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(['class'], 1))\n",
    "y = np.array(df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset\n",
    "Split the dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the classifier\n",
    "Now we will define the classifier, train it and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9857142857142858\n"
     ]
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try commenting the `df.drop(['id'])` line above and see how the id column is messing up with our model by checking the accuracy.  \n",
    "<br>\n",
    "So the important point here to note is that, **removing meaningless data is as important as selecting good features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([[4,2,1,1,1,2,3,2,1]])\n",
    "prediction = clf.predict(test_data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
